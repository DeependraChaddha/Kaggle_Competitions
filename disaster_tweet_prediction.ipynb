{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize few rows of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 7613 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "print(f\"The training data has {train_data.shape[0]} rows\")\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize few rows of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing data has 3263 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "print(f\"The testing data has {len(test_data)} rows\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our input is the text of the tweet, keyword and location, but the keyword and location may be NaN. So we need to handle that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1                   Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4                              Forest fire near La Ronge Sask. Canada   \n",
      "2   5                   All residents asked to 'shelter in place' are ...   \n",
      "3   6                   13,000 people receive #wildfires evacuation or...   \n",
      "4   7                   Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "   id keyword location                                               text\n",
      "0   0                                  Just happened a terrible car crash\n",
      "1   2                   Heard about #earthquake is different cities, s...\n",
      "2   3                   there is a forest fire at spot pond, geese are...\n",
      "3   9                            Apocalypse lighting. #Spokane #wildfires\n",
      "4  11                       Typhoon Soudelor kills 28 in China and Taiwan\n"
     ]
    }
   ],
   "source": [
    "#Handling NaN values in training data and testing data\n",
    "train_data['keyword']=train_data['keyword'].fillna('')\n",
    "train_data['location']=train_data['location'].fillna('')\n",
    "test_data['keyword']=test_data['keyword'].fillna('')\n",
    "test_data['location']=test_data['location'].fillna('')\n",
    "\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, make a list of all the tweets, keywords and locations that are in the training set. \n",
    "\n",
    "Then, make a list of all the tweets,keywords and locations that are in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Training Tweets\n",
      "['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all', 'Forest fire near La Ronge Sask. Canada', \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\", '13,000 people receive #wildfires evacuation orders in California ', 'Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school ']\n",
      "Sample Training Keywords\n",
      "['', '', '', '', '']\n",
      "Sample Training Locations\n",
      "['', '', '', '', '']\n",
      "Sample Training Target\n",
      "[1, 1, 1, 1, 1]\n",
      "Sample Testing Tweets\n",
      "['Just happened a terrible car crash', 'Heard about #earthquake is different cities, stay safe everyone.', 'there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all', 'Apocalypse lighting. #Spokane #wildfires', 'Typhoon Soudelor kills 28 in China and Taiwan']\n",
      "Sample Testing Keywords\n",
      "['', '', '', '', '']\n",
      "Sample Testing Locations\n",
      "['', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "training_tweets = train_data.iloc[:, -2].tolist()\n",
    "training_keywords=train_data.iloc[:, 1].tolist()\n",
    "training_locations=train_data.iloc[:, 2].tolist()\n",
    "training_target=train_data.iloc[:, -1].tolist()\n",
    "testing_tweets=test_data.iloc[:, -1].tolist()\n",
    "testing_keywords=test_data.iloc[:, 1].tolist()\n",
    "testing_locations=test_data.iloc[:, 2].tolist()\n",
    "print(\"Sample Training Tweets\")\n",
    "print(training_tweets[:5])\n",
    "print(\"Sample Training Keywords\")\n",
    "print(training_keywords[:5])\n",
    "print(\"Sample Training Locations\")\n",
    "print(training_locations[:5])\n",
    "print(\"Sample Training Target\")\n",
    "print(training_target[:5])\n",
    "print(\"Sample Testing Tweets\")\n",
    "print(testing_tweets[:5])\n",
    "print(\"Sample Testing Keywords\")\n",
    "print(testing_keywords[:5])\n",
    "print(\"Sample Testing Locations\")\n",
    "print(testing_locations[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize tweets, keywords and locations separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small part of the tweet sequences for visualization:\n",
      "[[ 120 4634   25    5  869    9   22  264  139 1620 4635   90   41    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [ 190   46  230  800 6955 6956 1405    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]]\n",
      "<class 'numpy.ndarray'>\n",
      "Number of sequences:7613\n",
      "Size of each padded sequence:33\n"
     ]
    }
   ],
   "source": [
    "#make tokenizer object called tokenizer_1 for tweets and keywords\n",
    "tokenizer_1= Tokenizer(oov_token= 'OOV')\n",
    "tokenizer_1.fit_on_texts(training_tweets) #fitting only on training data\n",
    "word_index_1 = tokenizer_1.word_index\n",
    "\n",
    "\n",
    "#convert sentences to sequences of integers\n",
    "tweet_sequences = tokenizer_1.texts_to_sequences(training_tweets) #uses the vocabulary learned from fitting on training data tweets\n",
    "padded_tweet_sequences = pad_sequences(tweet_sequences, padding= 'post') #pads sequences to maxlen\n",
    "\n",
    "#check the shape of padded sequences\n",
    "print(f\"small part of the tweet sequences for visualization:\\n{padded_tweet_sequences[:2]}\")\n",
    "print(type(padded_tweet_sequences))\n",
    "print(f\"Number of sequences:{padded_tweet_sequences.shape[0]}\")\n",
    "print(f\"Size of each padded sequence:{padded_tweet_sequences.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small part of keyword sequences for visualization \n",
      "[[0 0 0]\n",
      " [0 0 0]]\n",
      "datatype of padded_keyword_sequences: <class 'numpy.ndarray'>\n",
      "Number of keyword sequences: 7613\n",
      "Number of keywords in each sequence: 3\n"
     ]
    }
   ],
   "source": [
    "#tokenize keywords\n",
    "keyword_sequences=tokenizer_1.texts_to_sequences(training_keywords)\n",
    "padded_keyword_sequences=pad_sequences(keyword_sequences,padding='post')\n",
    "print(f\"small part of keyword sequences for visualization \\n{padded_keyword_sequences[:2]}\")\n",
    "print(f\"datatype of padded_keyword_sequences: {type(padded_keyword_sequences)}\")\n",
    "print(f\"Number of keyword sequences: {padded_keyword_sequences.shape[0]}\")\n",
    "print(f\"Number of keywords in each sequence: {padded_keyword_sequences.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small part of location sequences for visualization \n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "<class 'numpy.ndarray'>\n",
      "Number of sequences:7613\n",
      "Size of each padded sequence:12\n"
     ]
    }
   ],
   "source": [
    "#tokenize locations\n",
    "#make tokenizer object called tokenizer_2 for locations\n",
    "tokenizer_2= Tokenizer(oov_token= 'OOV')\n",
    "tokenizer_2.fit_on_texts(training_locations) #fitting only on training data\n",
    "word_index_2 = tokenizer_2.word_index\n",
    "\n",
    "\n",
    "#convert sentences to sequences of integers\n",
    "location_sequences = tokenizer_2.texts_to_sequences(training_locations) #uses the vocabulary learned from fitting on training data tweets\n",
    "padded_location_sequences = pad_sequences(location_sequences, padding= 'post') #pads sequences to maxlen\n",
    "\n",
    "#check the shape of padded sequences\n",
    "print(f\"small part of location sequences for visualization \\n {padded_location_sequences[0:2]}\")\n",
    "print(type(padded_location_sequences))\n",
    "print(f\"Number of sequences:{padded_location_sequences.shape[0]}\")\n",
    "print(f\"Size of each padded sequence:{padded_location_sequences.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have to embed the tweets, keywords and locations into a vector space. I will use smae vector embedding for tweets and keywords, and a separate one for locations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
